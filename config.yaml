# General settings
experiment_name: "ARNIQA_Experiment"
device: 0
seed: 27
data_base_path: "E:/ARNIQA - SE/ARNIQA/dataset/KADID10K"
checkpoint_base_path: "E:/ARNIQA - SE/ARNIQA/experiments/my_experiment/regressors"
checkpoint_frequency: 1

# Training
training:
  epochs: 10
  learning_rate: !!float 1e-3
  batch_size: 16
  num_workers: 20
  log_images_frequency: 1000
  resume_training: false
  step_size: 5
  gamma: 0.1
  dropout_rate: 0.1
  data:
    patch_size: 224
    max_distortions: 4
    num_levels: 5
    pristine_prob: 0.05
    augmentations:
      horizontal_flip: true
      rotation: 15
      color_jitter:
        brightness: 0.2
        contrast: 0.2
        saturation: 0.2
        hue: 0.1
      gaussian_blur: true
      normalize:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
  optimizer:
    name: SGD
    momentum: 0.9
    weight_decay: !!float 1e-4
    lr_scheduler_type: cosine
  lr_scheduler:
    name: CosineAnnealingWarmRestarts
    T_0: 1
    T_mult: 2
    eta_min: !!float 1e-6

# Validation
validation:
  frequency: 1
  num_splits: 10
  alpha: 0.1
  visualize: true
  early_stopping:
    patience: 5
    min_delta: 0.001
  datasets:
    - kadid10k

# Test
test:
  batch_size: 16
  num_workers: 20
  num_splits: 10
  grid_search: true
  alpha: 0.1
  tta: 5
  datasets:
    #- tid2013
    - kadid10k
    #- spaq

# Model
model:
  temperature: 0.1
  encoder:
    embedding_dim: 128
    pretrained: true
    use_norm: true
  se_block:
    use_se: true
    reduction: 16
    activation: relu

# Logging
logging:
  use_wandb: false
